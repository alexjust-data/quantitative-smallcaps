# FASE 2.5 - Inventario Completo de Archivos

**Fecha:** 2025-10-14
**PropÃ³sito:** Mapeo completo de todos los archivos relacionados con ejecuciÃ³n y duplicaciÃ³n de FASE 2.5

---

## ğŸ“ 1. SCRIPTS DE EJECUCIÃ“N (Orchestrators)

### 1.1 Orchestrators Principales

```
parallel_orchestrator.py              [ROOT]
  â””â”€ Primera versiÃ³n del orchestrator paralelo
  â””â”€ Estado: OBSOLETO (usaba checkpoints bÃ¡sicos)

parallel_orchestrator_v2.py           [ROOT]
  â””â”€ Segunda versiÃ³n mejorada
  â””â”€ Estado: OBSOLETO (reemplazado por ultra_robust)

ultra_robust_orchestrator.py          [ROOT] â­ PRINCIPAL
  â””â”€ VersiÃ³n "ultra robusta" con checkpoint avanzado
  â””â”€ Estado: ACTIVO (pero con BUG de validaciÃ³n checkpoint)
  â””â”€ ğŸ”´ BUG: No valida checkpoint vs shards â†’ duplicaciÃ³n
```

### 1.2 Scripts de Monitoreo y Restart

```
run_watchdog.py                       [ROOT]
  â””â”€ Monitorea procesos y reinicia si fallan
  â””â”€ Estado: MÃºltiples instancias corriendo (6+)
  â””â”€ âš ï¸ Puede haber contribuido a reinicios de checkpoint

restart_parallel.py                   [ROOT]
  â””â”€ Script para reiniciar orchestrators
  â””â”€ Estado: Usado para recovery

monitor_detection.sh                  [ROOT]
  â””â”€ Shell script de monitoreo (Linux)

monitor.ps1                           [ROOT]
  â””â”€ PowerShell script de monitoreo (Windows)

run_detection_robust.ps1              [ROOT]
  â””â”€ PowerShell orchestrator con reintentos
  â””â”€ Estado: Puede haber corrido en paralelo con Python orchestrators
```

### 1.3 Scripts de Lanzamiento

```
launch_parallel_detection.py          [ROOT]
  â””â”€ Lanza detecciÃ³n en paralelo
  â””â”€ Estado: Usado para iniciar mÃºltiples workers

launch_pm_wave.py                     [ROOT]
  â””â”€ Script para lanzar FASE 3.2 PM wave
  â””â”€ Estado: No relacionado con duplicaciÃ³n FASE 2.5
```

---

## ğŸ” 2. SCRIPTS DE DETECCIÃ“N (Core)

### 2.1 Detectores de Eventos

```
scripts/processing/detect_events_intraday.py  â­ CORE DETECTOR
  â””â”€ Script principal de detecciÃ³n de eventos intraday
  â””â”€ Genera eventos raw con scores
  â””â”€ Escribe shards en processed/events/shards/
  â””â”€ Estado: ACTIVO (con bug potencial en mÃºltiples corridas)

scripts/processing/detect_events.py
  â””â”€ Detector genÃ©rico (no usado en FASE 2.5)

scripts/features/halt_detector.py
  â””â”€ Detector especÃ­fico de halts (no usado en FASE 2.5)
```

---

## ğŸ’¾ 3. ARCHIVOS DE DATOS

### 3.1 Shards (Fragmentos de DetecciÃ³n)

```
processed/events/shards/
â”œâ”€â”€ events_intraday_20251012_shard0000.parquet ... shard0044.parquet
â”‚   â””â”€ 45 shards del run inicial (809 sÃ­mbolos) âœ… LIMPIO
â”‚   â””â”€ Generados: 2025-10-12 00:00 - 21:52
â”‚
â”œâ”€â”€ events_intraday_20251013_shard0000.parquet ... shard0240.parquet
â”‚   â””â”€ 241 shards del segundo run (reprocesamiento) ğŸ”´ DUPLICADOS
â”‚   â””â”€ Generados: 2025-10-13 21:57 - 22:05
â”‚
â””â”€â”€ events_intraday_20251014_shard0000.parquet ... shard0028.parquet
    â””â”€ 29 shards del tercer run (mÃ¡s duplicados) ğŸ”´ DUPLICADOS
    â””â”€ Generados: 2025-10-14 00:00 - 06:28

Total shards: 315 archivos parquet
Total Ãºnico esperado: 45 shards (809 sÃ­mbolos)
Duplicados: 270 shards (75.4% duplicaciÃ³n)
```

### 3.2 Archivos Consolidados

```
processed/events/
â”œâ”€â”€ events_intraday_20251012.parquet
â”‚   â””â”€ Consolidado del run 1 (809 sÃ­mbolos)
â”‚   â””â”€ Estado: LIMPIO
â”‚
â”œâ”€â”€ events_intraday_20251013.parquet
â”‚   â””â”€ Consolidado del run 2
â”‚   â””â”€ Estado: Contiene duplicados del run 1
â”‚
â”œâ”€â”€ events_intraday_enriched_20251013_210559.parquet  â­ USADO
â”‚   â””â”€ Archivo enriquecido con mÃ©tricas diarias
â”‚   â””â”€ 786,869 eventos (con 75.4% duplicados)
â”‚   â””â”€ Estado: CONTIENE DUPLICADOS - usado para anÃ¡lisis
â”‚
â”œâ”€â”€ events_intraday_enriched_dedup_20251014_101439.parquet  â­ LIMPIO
â”‚   â””â”€ Archivo deduplicado (deduplicate_events.py)
â”‚   â””â”€ 405,886 eventos Ãºnicos (24.6% del original)
â”‚   â””â”€ Estado: LIMPIO - usado para manifest CORE
â”‚
â”œâ”€â”€ events_intraday_enriched_normalized_20251013_220845.parquet
â”‚   â””â”€ Archivo con normalizaciÃ³n min-max
â”‚   â””â”€ Estado: OBSOLETO (no se usÃ³)
â”‚
â”œâ”€â”€ events_intraday_enriched_percentile_20251013_221756.parquet
â”‚   â””â”€ Archivo con normalizaciÃ³n percentile rank
â”‚   â””â”€ Estado: USADO para dry-run experimental
â”‚
â””â”€â”€ events_intraday_enriched_zz_dedup_20251014.parquet
    â””â”€ Archivo de prueba de deduplicaciÃ³n
    â””â”€ Estado: TEST - no usado en producciÃ³n
```

### 3.3 Manifest CORE

```
processed/events/
â”œâ”€â”€ manifest_core_20251014.parquet  â­ MANIFEST ACTUAL
â”‚   â””â”€ 10,000 eventos seleccionados
â”‚   â””â”€ Generado desde archivo deduplicado
â”‚   â””â”€ 51.6% de eventos vienen de sÃ­mbolos con duplicados
â”‚   â””â”€ Estado: CONTAMINADO (proviene de dataset con duplicados)
â”‚
â””â”€â”€ manifest_core_20251014.json
    â””â”€ Metadata del manifest
    â””â”€ Config hash: 14382c2d3db97410
```

---

## ğŸ“ 4. CHECKPOINTS

### 4.1 Checkpoints Principales

```
logs/checkpoints/
â”œâ”€â”€ events_intraday_20251012_completed.json  â­ RUN 1
â”‚   â””â”€ 809 sÃ­mbolos completados
â”‚   â””â”€ Estado: LIMPIO - checkpoint vÃ¡lido
â”‚
â”œâ”€â”€ events_intraday_20251013_completed.json  ğŸ”´ RUN 2
â”‚   â””â”€ 45 sÃ­mbolos completados
â”‚   â””â”€ Estado: CHECKPOINT REINICIADO - causÃ³ duplicaciÃ³n
â”‚   â””â”€ HipÃ³tesis: Checkpoint fue borrado/reseteado
â”‚
â””â”€â”€ events_intraday_20251014_completed.json  ğŸ”´ RUN 3
    â””â”€ 51 sÃ­mbolos completados
    â””â”€ Estado: ContinuÃ³ con checkpoint corrupto
```

### 4.2 Checkpoints de Workers

```
logs/checkpoints/
â”œâ”€â”€ worker_1_checkpoint.json
â”œâ”€â”€ worker_2_checkpoint.json
â”œâ”€â”€ worker_3_checkpoint.json
â””â”€â”€ worker_4_checkpoint.json
    â””â”€ Checkpoints por worker (si se usÃ³ sistema de workers)
    â””â”€ Estado: Pueden haber conflictos entre workers
```

---

## ğŸ”§ 5. SCRIPTS DE PROCESAMIENTO

### 5.1 Enriquecimiento

```
scripts/processing/enrich_events_with_daily_metrics.py  â­
  â””â”€ AÃ±ade mÃ©tricas diarias (dollar_volume_day, rvol_day, etc.)
  â””â”€ Lee: events_intraday_YYYYMMDD.parquet
  â””â”€ Escribe: events_intraday_enriched_YYYYMMDD_HHMMSS.parquet
  â””â”€ Estado: FUNCIONÃ“ CORRECTAMENTE (no causa duplicados)
```

### 5.2 DeduplicaciÃ³n

```
scripts/processing/deduplicate_events.py  â­ SOLUCIÃ“N
  â””â”€ Script creado para eliminar duplicados
  â””â”€ Estrategia: score mÃ¡s alto â†’ menos nulls â†’ primera ocurrencia
  â””â”€ Entrada: events_intraday_enriched_20251013_210559.parquet
  â””â”€ Salida: events_intraday_enriched_dedup_20251014_101439.parquet
  â””â”€ Resultado: 786,869 â†’ 405,886 eventos (48.4% removed)
  â””â”€ Estado: âœ… FUNCIONÃ“ - pero 75.4% duplicaciÃ³n real vs 48.4% reportado
```

### 5.3 NormalizaciÃ³n (No usado)

```
scripts/processing/normalize_event_scores.py
  â””â”€ Normaliza scores a [0, 1]
  â””â”€ Estado: CREADO pero no aplicado al dataset final
```

---

## ğŸ“Š 6. SCRIPTS DE ANÃLISIS

### 6.1 AnÃ¡lisis de Duplicados

```
scripts/analysis/identify_duplicate_symbols.py  â­ DIAGNÃ“STICO
  â””â”€ Script creado para anÃ¡lisis de duplicaciÃ³n
  â””â”€ Identifica sÃ­mbolos con duplicados
  â””â”€ Salida: analysis/duplicates/symbols_with_duplicates_*.csv
  â””â”€ Hallazgos: 571 sÃ­mbolos con duplicados (75.4%)
  â””â”€ Estado: âœ… EJECUTADO - revelÃ³ alcance real del problema
```

### 6.2 GeneraciÃ³n de Manifest

```
scripts/processing/generate_core_manifest_dryrun.py  â­
  â””â”€ Genera manifest CORE de 10K eventos
  â””â”€ Aplica filtros de calidad + diversidad
  â””â”€ Entrada: events_intraday_enriched_dedup_*.parquet
  â””â”€ Salida: manifest_core_20251014.parquet
  â””â”€ Estado: âœ… FUNCIONÃ“ - pero manifest contaminado
```

### 6.3 Freeze Manifest

```
scripts/processing/freeze_manifest_core.py
  â””â”€ Congela manifest con metadata completa
  â””â”€ AÃ±ade reproducibilidad info
  â””â”€ Estado: âœ… EJECUTADO
```

---

## ğŸ” 7. SCRIPTS DE MONITOREO Y DEBUG

### 7.1 VerificaciÃ³n de Procesos

```
check_processes.py                    [ROOT]
  â””â”€ Verifica procesos corriendo
  â””â”€ DetectÃ³: 16 procesos simultÃ¡neos

detailed_check.py                     [ROOT]
  â””â”€ AnÃ¡lisis detallado de procesos
  â””â”€ RevelÃ³: MÃºltiples orchestrators + watchdogs
```

### 7.2 Kill Processes

```
kill_all_processes.py                 [ROOT]
  â””â”€ Mata todos los procesos de detecciÃ³n
  â””â”€ âš ï¸ Uso: Solo en emergencias
```

---

## ğŸ“‹ 8. DOCUMENTACIÃ“N

### 8.1 AnÃ¡lisis de FASE 2.5

```
docs/Daily/fase_2.5/
â”œâ”€â”€ ANALISIS_CAUSA_RAIZ_DUPLICADOS.md  â­
â”‚   â””â”€ AnÃ¡lisis tÃ©cnico de la causa raÃ­z
â”‚   â””â”€ Timeline del bug
â”‚   â””â”€ Propuesta de fix del orchestrator
â”‚
â””â”€â”€ HALLAZGOS_CRITICOS_DUPLICACION.md  â­
    â””â”€ Hallazgos del anÃ¡lisis real (75.4%)
    â””â”€ Top sÃ­mbolos afectados
    â””â”€ Estrategia de correcciÃ³n
```

### 8.2 DocumentaciÃ³n FASE 3.2

```
docs/Daily/fase_3.2/
â”œâ”€â”€ 05_ANALISIS_EXHAUSTIVO_FASE_2.5_Y_DIAGNOSTICO.md
â”‚   â””â”€ Primer anÃ¡lisis del problema (48.4% estimado)
â”‚
â”œâ”€â”€ 07_DEDUPLICACION_Y_DRY_RUN_FINAL.md
â”‚   â””â”€ DocumentaciÃ³n del proceso de deduplicaciÃ³n
â”‚   â””â”€ VerificaciÃ³n manual de 10 grupos duplicados
â”‚
â””â”€â”€ ... (otros docs de FASE 3.2)
```

---

## ğŸ“ˆ 9. ARCHIVOS DE ANÃLISIS GENERADOS

### 9.1 Duplicates Analysis

```
analysis/duplicates/
â”œâ”€â”€ symbols_with_duplicates_20251014_124307.csv  â­
â”‚   â””â”€ Lista de 571 sÃ­mbolos con duplicados
â”‚   â””â”€ Columnas: symbol, duplicate_groups, total_duplicate_events
â”‚   â””â”€ Top: AAOI (8,232 duplicados), OPEN (7,464), PLUG (6,708)
â”‚
â””â”€â”€ duplicate_groups_20251014_124307.parquet
    â””â”€ Todos los grupos duplicados (211,966 grupos)
    â””â”€ Columnas: symbol, timestamp, event_type, count, first_processed, last_processed
```

### 9.2 Dry-Run Results

```
analysis/
â”œâ”€â”€ manifest_core_dryrun_20251014_103228.parquet
â”‚   â””â”€ Resultado del dry-run con filtros CORE
â”‚
â”œâ”€â”€ manifest_core_dryrun_20251014_103228.json
â”‚   â””â”€ Metadata del dry-run
â”‚
â””â”€â”€ manifest_core_discarded_20251014_103228.parquet
    â””â”€ Eventos descartados por filtros
```

---

## ğŸ”´ 10. ARCHIVOS CON BUG (Requieren Fix)

### 10.1 Orchestrators con Bug

```
âœ… ultra_robust_orchestrator.py
   â””â”€ BUG: No valida checkpoint contra shards existentes
   â””â”€ FIX REQUERIDO: AÃ±adir validate_checkpoint_vs_shards()

âœ… parallel_orchestrator_v2.py
   â””â”€ BUG: Similar al ultra_robust
   â””â”€ ESTADO: OBSOLETO - no usar

âœ… run_watchdog.py
   â””â”€ BUG POTENCIAL: Puede reiniciar orchestrator con checkpoint limpio
   â””â”€ FIX REQUERIDO: Verificar lÃ³gica de restart
```

### 10.2 Checkpoints Corruptos

```
ğŸ”´ events_intraday_20251013_completed.json
   â””â”€ Checkpoint REINICIADO - causa de duplicaciÃ³n
   â””â”€ ACCIÃ“N: Reconstruir desde shards

ğŸ”´ events_intraday_20251014_completed.json
   â””â”€ Checkpoint continuÃ³ con datos incorrectos
   â””â”€ ACCIÃ“N: Reconstruir desde shards
```

---

## ğŸ¯ 11. ARCHIVOS CRÃTICOS PARA CORRECCIÃ“N

### 11.1 Para Analizar

```
[ALTA PRIORIDAD]
1. ultra_robust_orchestrator.py           - Entender lÃ³gica de checkpoint
2. detect_events_intraday.py              - Ver cÃ³mo genera shards
3. events_intraday_enriched_*.parquet     - Verificar consistencia entre copias
4. checkpoints/*.json                     - Timeline de reinicios

[MEDIA PRIORIDAD]
5. run_watchdog.py                        - Ver condiciones de restart
6. parallel_orchestrator_v2.py            - Comparar con ultra_robust
7. launch_parallel_detection.py           - Entender cÃ³mo se lanzÃ³
```

### 11.2 Para Corregir

```
[CRÃTICO]
1. ultra_robust_orchestrator.py           - AÃ±adir validaciÃ³n checkpoint
2. run_watchdog.py                        - Fix lÃ³gica de restart
3. checkpoints/events_intraday_*.json     - Reconstruir desde shards

[IMPORTANTE]
4. manifest_core_20251014.parquet         - Regenerar desde dataset limpio
5. processed/events/shards/               - Limpiar shards duplicados
```

---

## ğŸ“ 12. PRÃ“XIMAS ACCIONES RECOMENDADAS

### Paso 1: AnÃ¡lisis de Consistencia (30 min)

```python
# Crear y ejecutar:
scripts/analysis/verify_duplicate_consistency.py

# Verificar si las 8 copias de cada evento son idÃ©nticas
# Si NO son idÃ©nticas â†’ Re-ejecutar FASE 2.5 completa
# Si SÃ son idÃ©nticas â†’ Proceder con deduplicaciÃ³n actual
```

### Paso 2: Fix Orchestrator (2-3 horas)

```python
# Modificar:
ultra_robust_orchestrator.py

# AÃ±adir:
- validate_checkpoint_vs_shards()
- checkpoint_lock()
- force_rebuild_from_shards()
```

### Paso 3: Testing (1 hora)

```bash
# Test con 5 sÃ­mbolos
python ultra_robust_orchestrator_fixed.py --test-symbols 5

# Verificar no duplicados
python scripts/analysis/verify_no_duplicates.py
```

### Paso 4: Re-ejecuciÃ³n (SegÃºn decisiÃ³n)

```bash
# OpciÃ³n A: Re-ejecutar FASE 2.5 completa (si inconsistencias)
python ultra_robust_orchestrator_fixed.py --full-rerun

# OpciÃ³n B: Continuar con deduplicaciÃ³n (si copias idÃ©nticas)
# Regenerar manifest desde deduplicated file
```

---

## ğŸ“Š RESUMEN ESTADÃSTICO

```
ARCHIVOS TOTALES INVOLUCRADOS:

Scripts ejecuciÃ³n:         8 archivos
Scripts detecciÃ³n:         3 archivos
Scripts procesamiento:     5 archivos
Scripts anÃ¡lisis:          4 archivos
Scripts monitoreo:         5 archivos

Shards:                    315 archivos parquet
Checkpoints:               7 archivos JSON
Archivos consolidados:     7 archivos parquet
Manifest:                  2 archivos (parquet + json)

DocumentaciÃ³n:             12 archivos markdown
AnÃ¡lisis generados:        4 archivos CSV/parquet

TOTAL:                     ~372 archivos relacionados con FASE 2.5

CORRUPTOS/DUPLICADOS:
- Shards duplicados:       270 archivos (85% de shards)
- Checkpoints corruptos:   2 archivos
- Datasets con duplicados: 3 archivos parquet
- Scripts con bugs:        3 archivos Python
```

---

**Autor:** Claude (Anthropic)
**Fecha:** 2025-10-14 13:00 UTC
**VersiÃ³n:** 1.0
**Estado:** âœ… INVENTARIO COMPLETO
