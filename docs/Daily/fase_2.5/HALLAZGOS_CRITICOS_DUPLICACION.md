# üî¥ FASE 2.5 - Hallazgos Cr√≠ticos: Duplicaci√≥n del 75.4%

**Fecha:** 2025-10-14 12:45 UTC
**Severidad:** üî¥ CR√çTICA EXTREMA
**Estado:** ‚úÖ IDENTIFICADO - Requiere acci√≥n inmediata

---

## ‚ùå SITUACI√ìN ACTUAL - PEOR DE LO ESTIMADO

### N√∫meros Reales (An√°lisis Completo)

```
Total eventos en archivo enriched:     786,869
Eventos √∫nicos (sin duplicados):       193,920 (24.6%)
Eventos duplicados:                    592,949 (75.4%)

Duplicate groups:                      211,966
S√≠mbolos afectados:                    571 (50.4% de 1,133)
Promedio duplicados/s√≠mbolo:           1,038.4 eventos
M√°ximo duplicados (AAOI):              8,232 eventos
```

### VS Estimaci√≥n Original

| M√©trica | Estimado | Real | Diferencia |
|---------|----------|------|------------|
| % Duplicaci√≥n | 48.4% | **75.4%** | +56% peor |
| S√≠mbolos afectados | 45-96 | **571** | 6-12x m√°s |
| Eventos duplicados | 380,983 | **592,949** | +56% m√°s |

---

## üî• TOP 10 S√çMBOLOS M√ÅS AFECTADOS

| # | Symbol | Duplicate Groups | Total Duplicates | Avg Copies |
|---|--------|------------------|------------------|------------|
| 1 | AAOI | 1,029 | 8,232 | 8.0x |
| 2 | OPEN | 1,866 | 7,464 | 4.0x |
| 3 | PLUG | 1,677 | 6,708 | 4.0x |
| 4 | ABAT | 796 | 6,368 | 8.0x |
| 5 | OPTT | 1,223 | 6,115 | 5.0x |
| 6 | AAL | 691 | 5,528 | 8.0x |
| 7 | ACHR | 1,256 | 5,024 | 4.0x |
| 8 | PLTR | 1,206 | 4,824 | 4.0x |
| 9 | PGY | 1,155 | 4,620 | 4.0x |
| 10 | PTON | 904 | 4,520 | 5.0x |

**Observaci√≥n cr√≠tica:** Algunos s√≠mbolos tienen **8 copias** por evento, sugiriendo que el orchestrator los reproces√≥ **8 veces completas**.

---

## üìä IMPACTO EN MANIFEST CORE

### Distribuci√≥n en Manifest

```
Total eventos en manifest CORE:        10,000
Eventos de s√≠mbolos con duplicados:    5,161 (51.6%)
Eventos de s√≠mbolos limpios:           4,839 (48.4%)

S√≠mbolos con duplicados en manifest:   522 (50.5% de 1,034)
S√≠mbolos limpios en manifest:          512 (49.5%)

Over-representation ratio:             1.05x
```

### Interpretaci√≥n

‚úÖ **Buenas noticias:**
- No hay over-representation significativa (solo 5% m√°s)
- El manifest est√° relativamente balanceado

‚ùå **Malas noticias:**
- **51.6% de manifest CORE** proviene de s√≠mbolos con calidad de datos cuestionable
- Estos s√≠mbolos fueron reprocesados 4-8 veces ‚Üí riesgo de **inconsistencias temporales**
- Si hay bugs en versiones del orchestrator, algunos eventos pueden tener campos incorrectos

---

## üîç CAUSA RA√çZ ACTUALIZADA

### Timeline Reconstruida (Actualizada)

```
2025-10-12 00:00-21:52  | Run 1: 809 s√≠mbolos ‚úÖ
2025-10-13 21:52        | üî¥ Checkpoint reset #1
2025-10-13 21:57-22:05  | Run 2: 45 s√≠mbolos (duplicados 2x)
2025-10-14 00:00-06:28  | Run 3: 51 s√≠mbolos (duplicados 3x)
                         | ...
                         | üî¥ Checkpoint reset #2, #3, #4, #5, #6, #7
                         | Runs 4-8: S√≠mbolos reprocesados m√∫ltiples veces
```

### Hip√≥tesis Revisada

**Causa m√°s probable:** M√∫ltiples orchestrators corriendo SIMULT√ÅNEAMENTE con conflictos de checkpoint

**Evidencia:**
1. 16 procesos detectados corriendo al mismo tiempo
2. Algunos s√≠mbolos con 8 copias exactas ‚Üí 8 corridas diferentes
3. Timestamps de `enriched_at` muestran procesamiento paralelo

**Escenario reconstruido:**
```
Orchestrator A: Procesa s√≠mbolo AAOI ‚Üí escribe checkpoint
Orchestrator B: Lee checkpoint antiguo ‚Üí reprocesa AAOI ‚Üí escribe checkpoint
Orchestrator C: Lee checkpoint de B ‚Üí reprocesa AAOI nuevamente
... (se repite 8 veces)
```

---

## üí∞ IMPACTO SI NO CORREGIMOS

### Desperdicio en FASE 3.2

```
Eventos en manifest:                   10,000
Eventos de s√≠mbolos duplicados:        5,161 (51.6%)

Asumiendo que 75% de estos son "extras" por duplicaci√≥n:
Eventos desperdiciados estimados:      3,871

Costo por evento:
  - Tiempo: 24s
  - Storage: 2.5 MB
  - API calls: 2 requests

Desperdicio total:
  - Tiempo: 3,871 √ó 24s = 25.8 horas
  - Storage: 3,871 √ó 2.5MB = 9.7 GB
  - API calls: 7,742 requests (~$38-77)
  - Tiempo de an√°lisis posterior: incalculable
```

### Riesgo de Calidad de Datos

**Cr√≠tico:** Si el orchestrator ten√≠a bugs entre las 8 corridas:
- Versiones diferentes pueden haber calculado `score` diferente
- Campos `enriched_at`, `session`, `tier` pueden ser inconsistentes
- Selecci√≥n de "mejor" evento en deduplicaci√≥n puede haber sido incorrecta

**Ejemplo:**
```
AAOI evento @ 2024-05-31 13:30:
  - Copia 1 (run 1): score=45.3, session=RTH
  - Copia 2 (run 2): score=45.3, session=RTH
  - Copia 3 (run 3): score=45.3, session=RTH  (BUG: mal c√°lculo)
  - ...
  - Copia 8 (run 8): score=45.3, session=RTH

Deduplicaci√≥n mantiene: Copia con score m√°s alto + menos nulls
‚Üí Puede haber seleccionado la copia con el BUG
```

---

## ‚úÖ ESTRATEGIA DE CORRECCI√ìN REVISADA

### Paso 1: An√°lisis Adicional (1 hora)

**Verificar inconsistencias entre copias:**
```python
# Script: scripts/analysis/verify_duplicate_consistency.py

# Para cada grupo duplicado, verificar si todas las copias son id√©nticas
for group in duplicate_groups:
    copies = df.filter(...)

    # Comparar campos cr√≠ticos
    fields_to_check = ['score', 'session', 'tier', 'dollar_volume', 'rvol_day']

    for field in fields_to_check:
        if copies[field].n_unique() > 1:
            print(f"WARNING: {group} has inconsistent {field}")
            print(copies.select(['symbol', 'timestamp', field]))
```

**Decisi√≥n seg√∫n resultados:**
- ‚úÖ **Si copias son 100% id√©nticas:** Proceder con deduplicaci√≥n actual
- ‚ùå **Si hay inconsistencias:** Re-ejecutar FASE 2.5 completa desde cero

### Paso 2: Decisi√≥n GO/NO-GO

**Opci√≥n A: Re-ejecutar FASE 2.5 Completa (RECOMENDADO si hay inconsistencias)**

Pros:
- ‚úÖ Dataset completamente limpio
- ‚úÖ Sin riesgo de bugs entre versiones
- ‚úÖ Reproducibilidad garantizada

Cons:
- ‚è≥ 1,133 s√≠mbolos √ó 12s = ~3.8 horas por corrida √ó 40 workers = ~2.3 d√≠as
- ‚è≥ Delay total: ~7 d√≠as (fix + re-run + FASE 3.2)

**Opci√≥n B: Continuar con Deduplicaci√≥n Actual (SI copias son id√©nticas)**

Pros:
- ‚úÖ No delay adicional
- ‚úÖ Proceder con FASE 3.2 en ~5 d√≠as

Cons:
- ‚ö†Ô∏è Riesgo residual de inconsistencias no detectadas
- ‚ö†Ô∏è Dataset con provenance cuestionable

### Paso 3: Fix del Orchestrator (2-3 horas)

**Bug identificado:**
```python
# ultra_robust_orchestrator.py

# ANTES (BUGGY):
def main():
    checkpoint = load_checkpoint()  # Solo lee del disco

    for symbol in get_pending_symbols(checkpoint):
        process_symbol(symbol)
        update_checkpoint(symbol)

# DESPU√âS (FIXED):
def main():
    checkpoint = load_checkpoint()

    # ‚úÖ VALIDACI√ìN CRUZADA
    checkpoint = validate_checkpoint_vs_shards(checkpoint, shards_dir)

    # ‚úÖ LOCK PARA EVITAR CONFLICTOS
    with checkpoint_lock():
        for symbol in get_pending_symbols(checkpoint):
            process_symbol(symbol)
            update_checkpoint(symbol)
```

**Implementaci√≥n:**
```python
def validate_checkpoint_vs_shards(checkpoint, shards_dir):
    """
    Cross-validate checkpoint against existing shards
    If shards exist for symbols NOT in checkpoint, rebuild checkpoint
    """
    import polars as pl
    from pathlib import Path

    # Get symbols from shards
    shard_symbols = set()
    for shard_file in Path(shards_dir).glob("shard*.parquet"):
        df_shard = pl.read_parquet(shard_file)
        shard_symbols.update(df_shard['symbol'].unique().to_list())

    # Get symbols from checkpoint
    checkpoint_symbols = set(checkpoint.get('completed_symbols', []))

    # Find missing symbols
    missing_in_checkpoint = shard_symbols - checkpoint_symbols

    if missing_in_checkpoint:
        logger.warning(f"Checkpoint missing {len(missing_in_checkpoint)} symbols found in shards!")
        logger.warning(f"Rebuilding checkpoint from shards...")

        # Rebuild checkpoint
        checkpoint['completed_symbols'] = list(shard_symbols)
        checkpoint['last_validated'] = datetime.now().isoformat()
        checkpoint['validation_source'] = 'shards'

        # Save corrected checkpoint
        save_checkpoint(checkpoint)

    return checkpoint


def checkpoint_lock():
    """
    File-based lock to prevent multiple orchestrators from conflicting
    """
    import fcntl
    import tempfile
    from contextlib import contextmanager

    lock_file = Path(tempfile.gettempdir()) / "fase25_checkpoint.lock"

    @contextmanager
    def _lock():
        with open(lock_file, 'w') as f:
            try:
                fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                yield
            except BlockingIOError:
                raise RuntimeError("Another orchestrator is already running! Use --force to override.")
            finally:
                fcntl.flock(f.fileno(), fcntl.LOCK_UN)

    return _lock()
```

### Paso 4: Testing del Fix (1 hora)

```bash
# Test con 5 s√≠mbolos
python ultra_robust_orchestrator_fixed.py --test-symbols 5

# Verificar que no genera duplicados
python scripts/analysis/verify_no_duplicates.py

# Test con m√∫ltiples orchestrators simult√°neos (deber√≠a fallar con lock)
python ultra_robust_orchestrator_fixed.py &
python ultra_robust_orchestrator_fixed.py &  # Deber√≠a fallar inmediatamente
```

---

## üéØ DECISI√ìN REQUERIDA

**¬øQu√© hacemos?**

### Opci√≥n 1: Verificar Consistencia Primero (1h) ‚Üí Decidir

```bash
python scripts/analysis/verify_duplicate_consistency.py

# Si 100% id√©nticas ‚Üí Opci√≥n A
# Si hay inconsistencias ‚Üí Opci√≥n B
```

### Opci√≥n 2A: Deduplicar y Continuar (5 d√≠as total)

1. ‚úÖ Usar deduplicated file actual
2. ‚úÖ Fix orchestrator para FASE 2.6+
3. ‚úÖ Proceder con FASE 3.2 (re-launch PM wave)

### Opci√≥n 2B: Re-ejecutar FASE 2.5 Completa (7 d√≠as total)

1. ‚úÖ Fix orchestrator
2. ‚úÖ Limpiar shards antiguos
3. ‚úÖ Re-ejecutar FASE 2.5 desde cero (1,133 s√≠mbolos)
4. ‚úÖ Regenerar manifest CORE
5. ‚úÖ Lanzar FASE 3.2 con dataset limpio

---

## üìù PR√ìXIMOS PASOS INMEDIATOS

1. **AHORA:** Crear script `verify_duplicate_consistency.py`
2. **30 min:** Ejecutar verificaci√≥n
3. **Decisi√≥n:** Seg√∫n resultados de consistencia
4. **2h:** Fix orchestrator
5. **1h:** Testing
6. **GO:** Re-ejecutar FASE 2.5 o continuar con deduplicaci√≥n

---

**Autor:** Claude (Anthropic)
**Fecha:** 2025-10-14 12:45 UTC
**Archivos generados:**
- `analysis/duplicates/symbols_with_duplicates_20251014_124307.csv`
- `analysis/duplicates/duplicate_groups_20251014_124307.parquet`
- `docs/Daily/fase_2.5/ANALISIS_CAUSA_RAIZ_DUPLICADOS.md`

**Estado:** ‚úÖ AN√ÅLISIS COMPLETO - Esperando decisi√≥n para continuar
