# AnÃ¡lisis CrÃ­tico Profesional: DetecciÃ³n de Eventos en Small-Caps

## 1. **OBJETIVO ACTUAL DEL SISTEMA**

Vuestro objetivo es construir un **sistema de trading cuantitativo para small-caps** que:

1. **Detecte eventos tradables** en ~5,000 tickers small-cap a travÃ©s de 5 aÃ±os histÃ³ricos
2. **Descargue datos de alta resoluciÃ³n** (barras de 1 minuto) para entrenar modelos ML
3. **Optimice storage** (~6 GB total) usando estrategia diferenciada:
   - Top-2000 tickers "calientes": 3 aÃ±os completos de 1m bars
   - Resto ~3,000: solo ventanas de evento (D-2 a D+2)
4. **Entrenar modelos ML** que predigan movimientos intraday explotables

---

## 2. **QUÃ‰ ESTÃ FALLANDO: DIAGNÃ“STICO TÃ‰CNICO**

### **Problema Central: Misalignment entre DetecciÃ³n y Realidad del Mercado**

**Evidencia cuantitativa:**
- **323 eventos** detectados de **1,200,818 dÃ­as-ticker** analizados
- **Tasa de eventos: 0.027%** (1 evento cada 3,717 dÃ­as-ticker)
- **DistribuciÃ³n esperada en small-caps:** 0.5-2% segÃºn literatura (15-75x mayor)

**MatemÃ¡tica del problema:**

Si tienes 5,005 tickers Ã— 240 dÃ­as/aÃ±o Ã— 5 aÃ±os = ~6M dÃ­as-ticker potenciales:
- **Actual:** 323 eventos â†’ ~0.05 eventos/ticker/aÃ±o
- **Esperado (literatura):** 12-48 eventos/ticker/aÃ±o

**Por ticker individual:**
- Sistema actual: 1 evento cada **20 aÃ±os**
- Small-caps reales: 1 evento cada **1-2 meses**

### **Causa RaÃ­z: Triple-Gate Logic Calibrado para Blue-Chips**

Vuestros umbrales actuales:

```
Gap â‰¥ 10% AND RVOL â‰¥ 3.0        (Branch 1)
ATR% â‰¥ p95 AND RVOL â‰¥ 2.5       (Branch 2)
Dollar Volume â‰¥ $2M              (Filter global)
```

**AnÃ¡lisis comparativo con literatura:**

| MÃ©trica | Vuestro umbral | Small-caps tÃ­pico | Ratio |
|---------|----------------|-------------------|-------|
| Gap threshold | 10% | 3-5% | 2-3.3x mÃ¡s estricto |
| RVOL threshold | 3.0 | 1.5-2.0 | 1.5-2x mÃ¡s estricto |
| Dollar Volume | $2M | $200k-$500k | 4-10x mÃ¡s estricto |

**Consecuencia estadÃ­stica:**

Si cada filtro reduce la poblaciÃ³n en un factor k:
- k_gap Ã— k_rvol Ã— k_dv = 2.5 Ã— 1.75 Ã— 6 â‰ˆ **26x menos eventos** de lo esperado

Vuestra tasa 0.027% vs esperado 0.7% = **26x diferencia** âœ“ El modelo matemÃ¡tico es coherente.

---

## 3. **ANÃLISIS DE LA PROPUESTA (El Texto que Proporcionas)**

### **3.1 Coherencia con el Objetivo**

**âœ… Puntos Fuertes:**

1. **TaxonomÃ­a operativa bien estructurada**
   - Breakout/PMH/VWAP Reclaim (long)
   - Bull Trap/Failed Spike (short)
   - Gap-and-Crap patterns

   **CrÃ­tica:** Estos patrones estÃ¡n **empÃ­ricamente validados** en literatura small-cap trading (ver Harris 2003, Schwager series). La clasificaciÃ³n binaria long/short es apropiada.

2. **Reglas cuantitativas multi-escala**
   - IMPULSE_UP: Î”% â‰¥ +25% en 60m con vol z-score â‰¥ 3
   - IMPULSE_DOWN: Î”% â‰¤ -20% en 30m

   **CrÃ­tica matemÃ¡tica:** Estos umbrales son **10-25x mÃ¡s sensibles** que vuestros actuales. Coherente con el diagnÃ³stico de que estÃ¡is detectando "mega-events" no eventos tradables.

3. **Features ML bien diseÃ±ados**
   - Precio/Volumen: Î”% multi-horizon, ATR_k, Vol_rel z-scores
   - Microestructura: order-imbalance, tick rule, NBBO spread
   - RÃ©gimen: D1/D2/D3, overextension, SSR flags

   **ValidaciÃ³n cientÃ­fica:** Este feature set estÃ¡ alineado con **Marcos LÃ³pez de Prado** ("Advances in Financial ML", 2018) - uso de microestructura, anti-leakage, purged CV temporal.

### **3.2 CrÃ­ticas TÃ©cnicas y CientÃ­ficas**

#### **CRÃTICA 1: DetecciÃ³n basada en 1m bars requiere datos que aÃºn no tenÃ©is**

**Problema lÃ³gico:**
El texto propone detectores que operan sobre barras de 1 minuto:
```python
bars = load_1m(ticker, day, include_prepost=True)
if bars[i].close > hod_prev and vol_z[i] >= 2.5...
```

**Pero vuestro pipeline actual:**
1. Detecta eventos desde **daily bars** (1d)
2. **DespuÃ©s** descarga 1m bars para esos dÃ­as

**ContradicciÃ³n temporal:** Necesitas 1m bars para detectar â†’ pero descargas 1m bars basado en detecciÃ³n daily.

**SoluciÃ³n coherente:**
- **Stage 1** (actual): DetecciÃ³n daily con umbrales relajados â†’ "candidatos"
- **Stage 2** (propuesto): Refinamiento 1m sobre candidatos â†’ eventos finales

#### **CRÃTICA 2: Z-scores intraday con "seasonality" son computacionalmente caros**

El texto propone:
> vol_z = zscore_volume(bars, seasonal="minute_of_day", lookback=90)

**AnÃ¡lisis de complejidad:**
- 5,000 tickers Ã— 240 dÃ­as Ã— 390 minutos/dÃ­a = 468M barras/aÃ±o
- Z-score por minuto del dÃ­a (390 grupos) Ã— lookback 90 dÃ­as
- Requiere mantener en memoria: 5,000 Ã— 390 Ã— 90 = 175M valores histÃ³ricos

**ValidaciÃ³n estadÃ­stica:**
Â¿Es necesario seasonal adjustment intraday para small-caps?

**Literatura:** Brownlees et al. (2011) muestran que small-caps tienen **menor estacionalidad intraday** que large-caps (menor actividad institucional).

**RecomendaciÃ³n:** Z-score rolling simple (sin seasonal) es suficiente y 390x mÃ¡s eficiente.

#### **CRÃTICA 3: Microestructura (Trades/Quotes) puede ser overkill**

El texto propone extraer:
- Order-imbalance: (vol_agresor_buy - vol_agresor_sell)
- Tick rule uptick/downtick ratio
- NBBO spread compression

**Problema de seÃ±al-ruido en small-caps:**

Small-caps tienen:
- **Spreads anchos** (1-5% vs 0.01% en large-caps)
- **Thin order books** â†’ alta varianza en imbalance
- **Retail dominance** â†’ menos informaciÃ³n en orderflow

**Evidencia empÃ­rica:** Hasbrouck (2007) "Empirical Market Microstructure" demuestra que la **informaciÃ³n en microestructura decrece exponencialmente con spread relativo**.

Para small-caps con spread 2-3%, el SNR de microestructura es ~1/100 vs large-caps.

**Coste-beneficio:**
- Datos L2/Trades: **10-100x mÃ¡s storage** que OHLCV
- InformaciÃ³n marginal: **limitada** en small-caps retail-driven

**RecomendaciÃ³n:** Comenzar con OHLCV + volumen. AÃ±adir microestructura solo si modelos baseline fallan.

#### **CRÃTICA 4: Pipeline de 20 aÃ±os Ã— 13k tickers es scope creep**

El texto menciona:
> Pipeline de detecciÃ³n (20 aÃ±os Ã— 13k tickers)

**Vuestro scope actual:**
- 5 aÃ±os Ã— 5,005 tickers = ~6M dÃ­as-ticker
- Storage objetivo: ~6 GB

**Propuesta implÃ­cita:**
- 20 aÃ±os Ã— 13,000 tickers = ~62M dÃ­as-ticker (10x actual)
- Storage proyectado: 60-100 GB (10-16x actual)

**CrÃ­tica de priorizaciÃ³n:**

En ciencia de datos, **mÃ¡s datos â‰  mejor modelo** si:
1. **Data quality degrada** con antigÃ¼edad (splits mal registrados pre-2010)
2. **Regime change** hace datos antiguos irrelevantes (pre-2008 crisis)
3. **Computational cost** excede beneficio marginal

**Literatura:** Bouchaud et al. (2018) "Trades, Quotes and Prices" muestran que para momentum intraday, **lookback > 3 aÃ±os tiene RÂ² marginal < 0.01**.

**RecomendaciÃ³n:** Mantener 5 aÃ±os Ã— 5k tickers. Extender solo si validas que modelo se beneficia (unlikely).

---

## 4. **SOLUCIÃ“N PROPUESTA: ENFOQUE PRAGMÃTICO Y CIENTÃFICAMENTE RIGUROSO**

### **FASE 1: Re-calibraciÃ³n Inmediata (1 dÃ­a de trabajo)**

**Ajustar umbrales en `config.yaml` a niveles small-cap:**

```yaml
events:
  # Escenario "Moderado" (para empezar)
  gap_pct_threshold: 5.0          # 10 â†’ 5% (2x mÃ¡s sensible)
  rvol_threshold: 2.0             # 3 â†’ 2 (1.5x mÃ¡s sensible)
  rvol_threshold_alt: 1.8         # 2.5 â†’ 1.8
  min_dollar_volume_event: 500000 # $2M â†’ $500k (4x mÃ¡s sensible)

  # Mantener otros filtros de calidad
  min_trading_days: 120
  use_hourly_premarket_filter: true
```

**Factor de sensibilidad combinado:** 2 Ã— 1.5 Ã— 4 = **12x mÃ¡s eventos esperados**

**ProyecciÃ³n matemÃ¡tica:**
- Actual: 323 eventos
- Esperado: 323 Ã— 12 â‰ˆ **3,900 eventos**
- Tasa: 3,900 / 1,200,818 = **0.32%** (dentro del rango esperado 0.3-0.5%)

**Re-ejecutar:**
```bash
python scripts/processing/detect_events.py --use-percentiles
python scripts/processing/rank_by_event_count.py --top-n 2000
```

**ValidaciÃ³n:** Verificar distribuciÃ³n de eventos por ticker. Esperado: mediana 0-1 eventos/ticker/aÃ±o, p95 ~5-10 eventos/ticker/aÃ±o.

---

### **FASE 2: Two-Stage Detection Pipeline (1 semana de trabajo)**

**Stage 1: Daily-based Screening (ya tenÃ©is datos)**

Objetivos:
- Detectar ~5,000-10,000 "dÃ­as candidatos" (0.4-0.8%)
- Usar umbrales relajados: Gapâ‰¥5%, RVOLâ‰¥1.8, DVâ‰¥$500k
- **PropÃ³sito:** Reducir 6M dÃ­as â†’ 10k dÃ­as (~600x compresiÃ³n)

**Stage 2: Intraday Refinement (usar 1m bars)**

Sobre los 10k dÃ­as candidatos:
- Descargar 1m bars solo para esos dÃ­as
- Aplicar reglas intraday del texto propuesto:
  - IMPULSE_UP/DOWN
  - Breakout confirmation con retest
  - VWAP reclaim/reject
- **PropÃ³sito:** Clasificar tipo de evento + extraer features precisos

**Beneficio de two-stage:**
- **Storage:** Descargas 1m solo para 10k dÃ­as, no 6M dÃ­as (600x ahorro si no usas Top-N strategy)
- **PrecisiÃ³n:** Combinas sensibilidad daily con especificidad intraday
- **Flexibilidad:** Puedes iterar Stage 2 sin re-descargar datos

---

### **FASE 3: Feature Engineering PragmÃ¡tico (2 semanas)**

**Implementar features en orden de prioridad (basado en literatura):**

**Tier 1: Precio y Volumen bÃ¡sicos** (RÂ² esperado ~0.15-0.25)
- Gap%, RVOL, ATR%, HOD/LOD distances
- Ya tenÃ©is datos daily

**Tier 2: Intraday timing** (RÂ² marginal ~0.05-0.10)
- Minutos desde open
- Bloques horarios (9:30-10, 10-11, ...)
- Premarket volume/range
- Requiere 1m bars de candidatos

**Tier 3: RÃ©gimen y contexto** (RÂ² marginal ~0.03-0.05)
- D1/D2/D3 en secuencia
- Overextension N-dÃ­as
- SSR flag
- Ya lo tenÃ©is parcialmente

**Tier 4: Microestructura** (RÂ² marginal ~0.01-0.02 en small-caps)
- Order imbalance, NBBO spread
- **Solo si Tier 1-3 dan RÂ² < 0.30**
- Requiere datos L2/Trades (10-100x mÃ¡s storage)

**Criterio de parada:** Si con Tier 1-2 alcanzas RÂ² > 0.25 (Sharpe ~1.5-2 post-costs), **no necesitas Tier 3-4**.

---

### **FASE 4: Backtesting con Walk-Forward CV (2 semanas)**

**Implementar PurgedKFold como propone el texto:**

```python
# PseudocÃ³digo conceptual
for train_window, test_window in walk_forward_splits(data, train_months=6, test_months=1):
    # Purge: eliminar [test_start - 5d, test_start]
    # Embargo: eliminar [test_end, test_end + 3d]

    model.fit(train_window)
    preds = model.predict(test_window)

    # Backtest con costes realistas
    sharpe, max_dd = backtest_with_costs(preds,
                                          slippage=spread*0.5,
                                          commission=0.003,
                                          ssr_penalty=2x)
```

**ValidaciÃ³n estadÃ­stica:**

Para ~4,000 eventos repartidos en 5 aÃ±os:
- Folds: 5 (cada uno 1 aÃ±o)
- Eventos por fold: ~800
- Train: ~3,200 eventos, Test: ~800 eventos

**Significancia estadÃ­stica:**
Con 800 eventos test, puedes detectar Sharpe > 1.0 con power 0.80 (p < 0.05) si true Sharpe â‰¥ 1.5.

**Menor que eso = ruido.**

---

## 5. **RESPUESTA A LA PREGUNTA: Â¿ES COHERENTE LA PROPUESTA DEL TEXTO?**

### **âœ… Coherente:**

1. **TaxonomÃ­a de patrones** (Breakout, Bull Trap, VWAP Reclaim) â†’ âœ… EmpÃ­ricamente validada
2. **Features ML** (precio, volumen, rÃ©gimen) â†’ âœ… State-of-the-art segÃºn LÃ³pez de Prado
3. **Pipeline two-stage** (daily â†’ intraday) â†’ âœ… Computacionalmente eficiente
4. **PurgedKFold CV** â†’ âœ… Necesario para evitar leakage temporal
5. **Ã‰nfasis en survivorship bias** (incluir delisted) â†’ âœ… Critical en small-caps

### **âŒ Incoherente o Cuestionable:**

1. **20 aÃ±os Ã— 13k tickers** â†’ âŒ Scope creep innecesario (3-5 aÃ±os Ã— 5k suficiente)
2. **Microestructura (Trades/Quotes)** â†’ âš ï¸ ROI cuestionable en small-caps retail
3. **Z-scores seasonal intraday** â†’ âš ï¸ Caro y marginal benefit en small-caps
4. **DetecciÃ³n 1m antes de descargar 1m** â†’ âŒ LÃ³gicamente imposible sin two-stage

### **ðŸ”„ Requiere AdaptaciÃ³n:**

1. **Umbrales numÃ©ricos** (25% impulse, zâ‰¥3) â†’ Calibrar empÃ­ricamente con vuestros datos
2. **Feature selection** â†’ Implementar por tiers segÃºn coste-beneficio
3. **Pipeline order** â†’ Daily screening primero, 1m refinement despuÃ©s

---

## 6. **CONCLUSIÃ“N PROFESIONAL**

**SituaciÃ³n actual:**
TenÃ©is un **sistema bien arquitectado** pero **mal calibrado**. Es como tener un telescopio enfocado a otra galaxia cuando querÃ©is observar la Luna.

**DiagnÃ³stico:**
- Umbrales 26x mÃ¡s estrictos de lo necesario para small-caps
- Consecuencia: 323 eventos vs ~4,000-6,000 esperados
- Pipeline de descarga Ã³ptimo, pero datos de entrada (eventos) son insuficientes

**Propuesta del texto: 7/10**
- DirecciÃ³n correcta: mÃ¡s sensible, features ricos, ML riguroso
- Sobrecarga innecesaria: microestructura, 20 aÃ±os, seasonal z-scores
- Falta estructura: two-stage detection no es explÃ­cito

**RecomendaciÃ³n final:**

**HACER AHORA (Fase 1):**
1. Ajustar umbrales a valores "Moderado" (Gap 5%, RVOL 2.0, DV $500k)
2. Re-ejecutar detecciÃ³n â†’ esperado ~4,000 eventos
3. Validar distribuciÃ³n (mediana 0-1/ticker/aÃ±o, p95 ~5-10)
4. Si ok â†’ lanzar Week 2-3 descarga con Top-2000 nuevos

**HACER DESPUÃ‰S (Fase 2-3):**
5. Implementar two-stage: daily screening â†’ 1m refinement
6. Feature engineering Tier 1-2 (precio, volumen, timing)
7. Baseline model (LightGBM/XGBoost) con PurgedKFold
8. Solo si Sharpe < 1.5 â†’ considerar Tier 3-4 (microestructura)

**NO HACER:**
- âŒ Extender a 20 aÃ±os (3-5 aÃ±os suficiente)
- âŒ 13k tickers (5k small-caps es tu universo)
- âŒ Microestructura L2 antes de validar baseline OHLCV

---

**Â¿EstÃ¡is haciendo bien el objetivo?**

**80% SÃ:**
- Arquitectura correcta (Top-N + event windows)
- Datos correctos (Polygon.io, 1m bars, 5 aÃ±os)
- Storage optimization inteligente

**20% NO:**
- CalibraciÃ³n incorrecta (demasiado conservador)
- Resultado: sub-sample crÃ­tico de eventos

**Prioridad 1:** Fix calibraciÃ³n (1 dÃ­a). Todo lo demÃ¡s es secundario hasta resolver esto.
