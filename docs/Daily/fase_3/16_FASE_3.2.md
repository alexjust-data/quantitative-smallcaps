Perfecto ‚Äî te explico con precisi√≥n d√≥nde est√°is, qu√© est√° haciendo el sistema ahora mismo, por qu√© se escogieron esos datos y hacia d√≥nde apunta todo el proceso üëá

---

## üß© D√≥nde estamos en el timeline

### üîπ FASE 2.5 ‚Üí **Detecci√≥n Intrad√≠a**

* Est√° corriendo (o reci√©n ha terminado) la **detecci√≥n de eventos intrad√≠a** sobre las barras de **1 minuto** descargadas previamente desde **Polygon.io**.
* Esas barras 1m son hist√≥ricas, no en streaming. Cubren unos **dos a√±os** por ~2.000 small caps.
* El resultado de esa fase es un gran fichero:
  `processed/events/events_intraday_YYYYMMDD.parquet`
  con ~370.000 eventos detectados (volume_spike, vwap_break, etc.).

üëâ En t√©rminos conceptuales, esta fase **no descarga m√°s datos**; solo analiza los 1m ya bajados y **marca los momentos importantes** dentro de cada d√≠a/s√≠mbolo.

---

### üîπ FASE 3.2 ‚Üí **Descarga Micro (Trades + Quotes)**

* Es la **fase siguiente**, que est√°s preparando ahora mismo.
* No usa toda la data, sino un subconjunto de los eventos detectados en 2.5 (los mejores ~10 000 seg√∫n calidad, liquidez, diversidad, etc.).
  Esa selecci√≥n se llama **CORE manifest**.
* A partir del manifest, el sistema ir√° a Polygon y descargar√°, para cada evento, una **ventana de microestructura**:

  ```
  [-3, +7] minutos alrededor del timestamp del evento
  ```

  obteniendo:

  * Trades (todas las ejecuciones reales)
  * Quotes (NBBO filtrado 5 Hz by-change-only)

**Objetivo:** disponer de datos ‚Äútick-by-tick‚Äù alrededor de los momentos m√°s informativos, para an√°lisis de order-flow, spread, desequilibrio, tape speed, etc.

---

## üßÆ Por qu√© se escogieron estos datos

1. **Base temporal:**
   Polygon ofrece barras 1m hist√≥ricas para miles de small caps ‚Üí es la granularidad m√≠nima que puedes cubrir a escala multianual sin petabytes.

2. **Micro-descarga selectiva:**
   Descargar ticks de todos los d√≠as ser√≠a inviable (‚âà 2.6 TB).
   Por eso se detectan eventos 1m y solo se bajan los **segmentos relevantes** (ventanas de 10 min) para unos pocos miles de ellos.

3. **Small Caps:**
   Porque ah√≠ se producen patrones de *pump & dump*, *gap & flush* y microestructuras explotables que son dif√≠ciles de modelar en large caps.

4. **Fuente Polygon.io:**
   Es adecuada para prototipado: ofrece trades, quotes (NBBO), aggregates y corporativos, con API REST consistente.
   En tiempo real tambi√©n puede emitir streaming WebSocket, as√≠ que en el futuro podr√°s conectar tu pipeline cient√≠fico a datos en vivo sin cambiar la estructura.

---

## üî≠ Hacia d√≥nde va el proceso

### 1Ô∏è‚É£ Corto plazo ‚Äî terminar FASE 2.5

* Esperar que acabe la detecci√≥n intrad√≠a completa (todos los s√≠mbolos).
* Validar cu√°ntos eventos y qu√© tipos predominan.

### 2Ô∏è‚É£ Inmediato ‚Äî construir el **CORE manifest**

* Aplicar filtros de calidad, liquidez y diversidad.
* Dejar el archivo `manifest_core_YYYYMMDD.parquet` como lista maestra de eventos para descarga micro.

### 3Ô∏è‚É£ Pr√≥ximo ‚Äî ejecutar FASE 3.2 (descarga micro)

* Descargar trades + quotes para los eventos del manifest.
* Validar cobertura y tama√±os (~30 GB estimados).

### 4Ô∏è‚É£ Medio plazo ‚Äî an√°lisis y modelos

* Calcular features microestructurales (spread, imbalance, tape speed‚Ä¶).
* Etiquetar con *triple barrier* o secuencias futuras.
* Entrenar modelos IA para predicci√≥n / screening de patrones.

### 5Ô∏è‚É£ Largo plazo ‚Äî streaming en tiempo real

* Conectar la arquitectura a Polygon WebSocket (u otro feed) para replicar la detecci√≥n y el scoring **en vivo**.
* La IA monitorizar√° tick-by-tick y lanzar√° alertas o ejecutar√° estrategias.

---

## üö¶ Posibles fallos cr√≠ticos antes de continuar

| Categor√≠a                  | Riesgo                                                                                              | Soluci√≥n                                                                    |
| -------------------------- | --------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------- |
| **Proceso Windows**        | Si la detecci√≥n 2.5 se ejecuta en background (&) puede cerrarse sola (~60 s).                       | Ejecutar **en primer plano con tee** o dentro de **WSL/Linux**.             |
| **Memoria**                | `detect_events_intraday.py` acumula todo en `all_events` antes de guardar ‚Üí puede agotar RAM.       | Procesar **por batches** (guardar cada 100 s√≠mbolos).                       |
| **Integridad de datos 1m** | Algunos s√≠mbolos no tienen datos 1m completos ‚Üí ‚ÄúNo bars file‚Äù.                                     | Confirmar `symbols_with_1m.parquet` actualizado y limitar a los v√°lidos.    |
| **Manifest sin dry-run**   | Si generas el manifest sin calibrar filtros (score/liquidez) puedes acabar con 0 o 100 000 eventos. | Ejecutar **`generate_core_manifest_dryrun.py`** primero y ajustar umbrales. |
| **Espacio disco**          | Si descargas trades+quotes para todo el universo ‚Üí >2 TB.                                           | Empezar con **perfil CORE** (10 K eventos, ~30 GB).                         |

---

## üß≠ En resumen

| Etapa        | Qu√© hace                                                           | Estado           |
| ------------ | ------------------------------------------------------------------ | ---------------- |
| **FASE 1**   | Descarga barras diarias, horarias y 1 m desde Polygon              | ‚úÖ completada     |
| **FASE 2**   | Detecci√≥n de eventos diarios                                       | ‚úÖ completada     |
| **FASE 2.5** | Detecci√≥n de eventos intrad√≠a sobre barras 1 m                     | ‚öôÔ∏è en curso      |
| **FASE 3.1** | An√°lisis y dry-run del manifest CORE                               | ‚úÖ en preparaci√≥n |
| **FASE 3.2** | Descarga trades + quotes tick-by-tick de los eventos seleccionados | ‚è≥ siguiente paso |
| **FASE 4**   | Feature engineering, labeling, modelado IA                         | üîú futura fase   |

---

‚úÖ **Conclusi√≥n:**
Est√°s justo en la **transici√≥n entre 2.5 y 3.2** ‚Äî detectando los eventos intrad√≠a dentro de los datos 1 min descargados, y preparando el manifest para decidir **qu√© eventos merecen bajarse a nivel micro**.

No hay fallos cr√≠ticos que impidan continuar, siempre que:

* ejecutes la detecci√≥n 2.5 en primer plano o en WSL, y
* generes el manifest CORE con el dry-run validado antes de lanzar descargas micro.
